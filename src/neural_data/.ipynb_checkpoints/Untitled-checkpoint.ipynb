{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5794d87b-e248-42ba-8ede-3ac86537ccc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "ROOT = '/ccn2/u/atlask/FYP/'\n",
    "sys.path.append(ROOT)\n",
    "\n",
    "from torchmetrics.functional import spearman_corrcoef, pearson_corrcoef\n",
    "\n",
    "from regression.regression import ridge_regression_cv_nc\n",
    "from data import load_repeated_file_paths, load_neural_data, process_words, convert_df_to_string\n",
    "from utils import match_tokens_and_average_embeddings\n",
    "\n",
    "import mne\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, LlamaForCausalLM\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pickle\n",
    "import yaml\n",
    "with open(f\"{ROOT}/paths.yaml\", \"r\") as f:\n",
    "    paths = yaml.safe_load(f)\n",
    "    \n",
    "DATA = paths[\"DATA\"]\n",
    "CACHE = paths[\"CACHE\"]\n",
    "\n",
    "os.makedirs(os.path.join(CACHE,'neural_preds'), exist_ok=True)\n",
    "os.makedirs(os.path.join(CACHE,'r_scores'), exist_ok=True)\n",
    "\n",
    "subjects = ['02','03','05','07','10','11']\n",
    "window_size = 10\n",
    "half_window = window_size // 2\n",
    "stride = 5\n",
    "    \n",
    "device = \"cuda\"\n",
    "\n",
    "\n",
    "all_neural_data_1 = []\n",
    "all_neural_data_2 = []\n",
    "\n",
    "# load neural data\n",
    "for subject in subjects:\n",
    "    \n",
    "    paths_1, paths_2 = load_repeated_file_paths(data_path=DATA, subject=subject)\n",
    "    paths_1.sort()\n",
    "    paths_2.sort()\n",
    "    \n",
    "    for i, stimulus_path_1 in enumerate(paths_1):\n",
    "        \n",
    "        epoch_1 = mne.read_epochs(f'{DATA}/{paths_1[i]}', preload=True).get_data()\n",
    "        epoch_2 = mne.read_epochs(f'{DATA}/{paths_2[i]}', preload=True).get_data()\n",
    "\n",
    "        epoch_1 = torch.Tensor(epoch_1).to(device)\n",
    "        epoch_2 = torch.Tensor(epoch_2).to(device)\n",
    "        \n",
    "        print('binning and averaging data')\n",
    "        \n",
    "\n",
    "        # Adjust the indexing to be centered around each value\n",
    "        epoch_1_binned = torch.stack(\n",
    "            [\n",
    "                epoch_1[:, :, max(0, i - half_window): i + half_window + 1].mean(dim=-1)\n",
    "                for i in range(half_window, epoch_1.shape[-1] - half_window, stride)\n",
    "            ],\n",
    "            dim=-1\n",
    "        )\n",
    "\n",
    "        epoch_2_binned = torch.stack([epoch_2[:,:, i:i + window_size].mean(dim=-1) for i in range(0, epoch_2.shape[-1] - window_size + 1, stride)],dim=-1)\n",
    "            \n",
    "        assert len(epoch_1_binned) == len(epoch_2_binned), 'the two lists should have the same number of sessions'\n",
    "        \n",
    "        all_neural_data_1.append(epoch_1_binned)\n",
    "        all_neural_data_2.append(epoch_2_binned)\n",
    "    \n",
    "    data_1 = torch.cat(all_neural_data_1, dim=0)\n",
    "    data_2 = torch.cat(all_neural_data_2, dim=0)\n",
    "    \n",
    "    all_scores = []\n",
    "    \n",
    "    for t_idx in tqdm(range(data_1.shape[-1])):\n",
    "    \n",
    "        r_values = pearson_corrcoef(data_1[:,:,t_idx], data_2[:,:,t_idx])\n",
    "        all_scores.append(r_values)\n",
    "        \n",
    "    \n",
    "    with open(os.path.join(CACHE,'r_scores',f\"noise_ceiling_subject={subject}\"), \"wb\") as file:\n",
    "        pickle.dump(all_scores, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5534bbc6-511d-439c-9382-40feebdba488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([825, 206])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_1[:,:, i:i + window_size].mean(dim=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "690c2a18-5725-4de1-9c60-41869b829868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([553, 206, 796])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([epoch_1[:,:, i:i + window_size].mean(dim=-1) for i in range(0, epoch_1.shape[-1] - window_size + 1, stride)],dim=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7626f565-4f37-4e71-951a-91a78b5be3a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([796, 553, 206])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([epoch_1[:,:, i:i + window_size].mean(dim=-1) for i in range(0, epoch_1.shape[-1] - window_size + 1, stride)],dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0aaac2b-325b-485c-b0dd-73a8de3f81b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
